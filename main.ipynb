{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import networkx as nx\n",
    "import pygraphviz as pgv\n",
    "import pandas as pd\n",
    "from pulp import LpProblem, LpMaximize, lpSum\n",
    "from ortoolpy import addbinvar, addvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradient():\n",
    "    colors = [\n",
    "        '#e53935',\n",
    "        '#e6353b',\n",
    "        '#e63241',\n",
    "        '#e62e47',\n",
    "        '#e62b4d',\n",
    "        '#e52852',\n",
    "        '#e52658',\n",
    "        '#e4255d',\n",
    "        '#e22463',\n",
    "        '#e12368',\n",
    "        '#df246e',\n",
    "        '#dc2573',\n",
    "        '#da2678',\n",
    "        '#d7287d',\n",
    "        '#d42a82',\n",
    "        '#d02d87',\n",
    "        '#cd308c',\n",
    "        '#c93391',\n",
    "        '#c43695',\n",
    "        '#c03999',\n",
    "        '#bb3c9e',\n",
    "        '#b63fa1',\n",
    "        '#b142a5',\n",
    "        '#ab45a9',\n",
    "        '#a548ac',\n",
    "        '#9f4aaf',\n",
    "        '#994db2',\n",
    "        '#9250b5',\n",
    "        '#8b52b7',\n",
    "        '#8454b9',\n",
    "        '#7d56bb',\n",
    "        '#7559bd',\n",
    "        '#6c5abe',\n",
    "        '#645cbf',\n",
    "        '#5b5ec0',\n",
    "        '#5160c0',\n",
    "        '#4661c1',\n",
    "        '#3a63c1',\n",
    "        '#2b64c0',\n",
    "        '#1565c0',\n",
    "    ]\n",
    "    colors2 = [\n",
    "        '#e53935',\n",
    "        '#e23e30',\n",
    "        '#e0422c',\n",
    "        '#dd4627',\n",
    "        '#da4a22',\n",
    "        '#d74d1d',\n",
    "        '#d45118',\n",
    "        '#d15413',\n",
    "        '#ce580c',\n",
    "        '#ca5b05',\n",
    "        '#c75e00',\n",
    "        '#c36000',\n",
    "        '#c06300',\n",
    "        '#bc6600',\n",
    "        '#b86800',\n",
    "        '#b46b00',\n",
    "        '#b16d00',\n",
    "        '#ad6f00',\n",
    "        '#a97100',\n",
    "        '#a57300',\n",
    "        '#a17500',\n",
    "        '#9d7700',\n",
    "        '#997800',\n",
    "        '#957a00',\n",
    "        '#917c00',\n",
    "        '#8d7d00',\n",
    "        '#897e00',\n",
    "        '#868000',\n",
    "        '#828100',\n",
    "        '#7e8200',\n",
    "        '#7a8300',\n",
    "        '#768404',\n",
    "        '#72850c',\n",
    "        '#6e8612',\n",
    "        '#6a8718',\n",
    "        '#66881d',\n",
    "        '#618922',\n",
    "        '#5d8a26',\n",
    "        '#598a2b',\n",
    "        '#558b2f',\n",
    "    ]\n",
    "    return ':'.join([color + ';0.025' for color in colors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_catalog():\n",
    "    with open('./aws-catalog.yml') as file:\n",
    "        return yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "def load_service_names():\n",
    "    catalog = load_catalog()\n",
    "    services = catalog['services']\n",
    "    service_names = [service['acronym'] if service['acronym'] is not None else service['name'] for service in services]\n",
    "    return service_names\n",
    "\n",
    "def load_acronyms():\n",
    "    catalog = load_catalog()\n",
    "    services = catalog['services']\n",
    "    services_with_acronym = list(filter(lambda service: service['acronym'] is not None, services))\n",
    "    terms_with_acronym = catalog['acronyms']\n",
    "    words_with_acronym = services_with_acronym + terms_with_acronym\n",
    "    acronyms = [word['acronym'] for word in words_with_acronym]\n",
    "    return acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_from_word(word):\n",
    "    return (word[0].upper(), word[-1].upper())\n",
    "\n",
    "def build_graph_from_all_edges(words):\n",
    "    graph = nx.MultiDiGraph()\n",
    "    graph.add_nodes_from(['start', 'end'])\n",
    "    for word in words:\n",
    "        (start, end) = get_nodes_from_word(word)\n",
    "        graph.add_edge(start, end, word=word, var=addbinvar())\n",
    "    \n",
    "    # Create edges from 'start'\n",
    "    # AWSしりとり starts from 'S' because 'AWS' precedes the first word\n",
    "    graph.add_edge('start', 'S', word='', var=addbinvar())\n",
    "    \n",
    "    # Create edges to 'end'\n",
    "    for node in list(graph.nodes)[2:]:\n",
    "        graph.add_edge(node, 'end', word='', var=addbinvar())\n",
    "    return graph\n",
    "\n",
    "def build_dataframe_from_graph(graph):\n",
    "    df = pd.DataFrame([(from_node, to_node, key, data['word'], data['var'])\n",
    "        for (from_node, to_node, key), data in graph.edges.items()],\n",
    "        columns=['From', 'To', 'Key', 'Word', 'Var'])\n",
    "    return df\n",
    "\n",
    "def build_problem(graph, df):\n",
    "    problem = LpProblem(sense=LpMaximize)\n",
    "    \n",
    "    # Objective: Maximize the number of edges\n",
    "    problem += lpSum(df.Var)\n",
    "    \n",
    "    # Constraint: Only one edge from 'start' and to 'end' respectively\n",
    "    problem += lpSum(df[df.From == 'start'].Var) == 1\n",
    "    problem += lpSum(df[df.To == 'end'].Var) == 1\n",
    "    \n",
    "    # Constraint: Any character node (not 'start' and 'end' node)\n",
    "    #   has the same number of edges that go into it and out of it\n",
    "    char_nodes = list(graph.nodes())[2:] # Nodes excluding 'start' and 'end'\n",
    "    for node in char_nodes:\n",
    "        problem += (lpSum([to_edge[2] for to_edge in graph.in_edges(node, data='var')])\n",
    "           == lpSum([from_edge[2] for from_edge in graph.edges(node, data='var')]))\n",
    "    return problem\n",
    "\n",
    "def build_graph_from_used_edges(df):\n",
    "    graph = nx.MultiDiGraph()\n",
    "    addvals(df)\n",
    "    for row in df[df.Val > 0.5].itertuples():\n",
    "        graph.add_edge(row.From, row.To, word=row.Word)\n",
    "    return graph\n",
    "\n",
    "def get_route(graph):\n",
    "    graph.add_edge('end', 'start') # Make the path an eulerian circuit\n",
    "    circuit = nx.eulerian_circuit(graph, 'start', True)\n",
    "    edges = list(circuit)[1:-2] # Exclude 'start' and 'end'\n",
    "    route = [graph[from_node][to_node][key]['word'] for from_node, to_node, key in edges]\n",
    "    return route\n",
    "\n",
    "def visualize_graph(original_graph):\n",
    "    graph = original_graph.copy()\n",
    "    \n",
    "    # Remove unnecessary nodes\n",
    "    graph.remove_node('start')\n",
    "    graph.remove_node('end')\n",
    "    \n",
    "    # Add styles to nodes\n",
    "    for node in graph.nodes():\n",
    "        graph.nodes[node]['shape'] = 'circle'\n",
    "        graph.nodes[node]['fontsize'] = '48'\n",
    "        graph.nodes[node]['fontname'] = 'arial'\n",
    "    \n",
    "    # Add styles to edges\n",
    "    for from_node, to_node, key, data in graph.edges(keys=True, data=True):\n",
    "        # graph.edges[from_node, to_node, key]['label'] = data['word'] # Too messy\n",
    "        graph.edges[from_node, to_node, key]['color'] = create_gradient()\n",
    "        graph.edges[from_node, to_node, key]['penwidth'] = '3'\n",
    "    \n",
    "    agraph = nx.nx_agraph.to_agraph(graph)\n",
    "    agraph.draw('outputs/file.svg', format='svg', prog='circo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = load_service_names()\n",
    "all_edges_graph = build_graph_from_all_edges(words)\n",
    "df = build_dataframe_from_graph(all_edges_graph)\n",
    "problem = build_problem(all_edges_graph, df)\n",
    "problem.solve()\n",
    "used_edges_graph = build_graph_from_used_edges(df)\n",
    "route = get_route(used_edges_graph)\n",
    "print(len(route), route)\n",
    "visualize_graph(all_edges_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
